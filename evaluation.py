# -*- coding: utf-8 -*-
"""Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gv57ukLGDiYzuAbVL80tjDO4bEHyxAfe
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import sys
import glob
import numpy as np
import argparse
import csv

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torchvision.models as models



class identity(nn.Module):
    def __init__(self):
        super(identity, self).__init__()

    def forward(self, x):
        return x

class mlp_module(nn.Module):
    def __init__(self):
        super(mlp_module, self).__init__()
        self.fc1 = nn.Linear(512, 512)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(512, 8+9+21)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.relu1(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

class FCTreeNet(nn.Module):
    def __init__(self, in_dim=300, img_dim=256):
        super(FCTreeNet, self).__init__()
        self.in_dim = in_dim
        self.img_dim = img_dim
        self.fc = nn.Linear(self.in_dim, self.in_dim)
        self.leaf = nn.Linear(self.in_dim + self.img_dim, self.img_dim)
        self.middle = nn.Linear(self.in_dim + self.img_dim, self.img_dim)
        self.merge = nn.Linear(self.in_dim + self.img_dim, self.img_dim)
        self.root = nn.Linear(self.in_dim + self.img_dim, self.img_dim)
        self.relu = nn.ReLU()

    def forward(self, image_feature, input, indicator):
        input = self.fc(input.view(-1, input.size(-1)))
        input = input.view(-1, 6, input.size(-1))
        input = input.unsqueeze(1).repeat(1, image_feature.size(1), 1, 1)
        indicator = indicator.unsqueeze(1).repeat(1, image_feature.size(1), 1).view(-1, 1)
        leaf_left = input[:, :, 3, :].view(-1, input.size(-1))
        leaf_right = input[:, :, 5, :].view(-1, input.size(-1))
        inter_left = input[:, :, 2, :].view(-1, input.size(-1))
        inter_right = input[:, :, 4, :].view(-1, input.size(-1))
        merge = input[:, :, 1, :].view(-1, input.size(-1))
        root = input[:, :, 0, :].view(-1, input.size(-1))

        leaf_left = torch.cat((leaf_left, image_feature.view(-1, image_feature.size(-1))), dim=-1)
        leaf_right = torch.cat((leaf_right, image_feature.view(-1, image_feature.size(-1))), dim=-1)
        out_leaf_left = self.relu(self.leaf(leaf_left))
        out_leaf_right = self.relu(self.leaf(leaf_right))
        out_left = self.relu(self.middle(torch.cat((inter_left, out_leaf_left), dim=-1)))
        out_right = self.relu(self.middle(torch.cat((inter_right, out_leaf_right), dim=-1)))
        out_right = torch.mul(out_right, indicator)
        out_merge = self.relu(self.merge(torch.cat((merge, out_left + out_right), dim=-1)))
        out_root = self.relu(self.root(torch.cat((root, out_merge), dim=-1)))
        return out_root

class Resnet18_MLP(nn.Module):
    def __init__(self, img_size=160):
        super(Resnet18_MLP, self).__init__()
        self.img_size = img_size
        self.resnet18 = models.resnet18(pretrained=False)
        self.resnet18.conv1 = nn.Conv2d(16, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.resnet18.fc = identity()
        self.mlp = mlp_module()
        self.fc_tree_net = FCTreeNet(in_dim=300, img_dim=512)

    def forward(self, x, embedding, indicator):
        alpha = 1.0

        features = self.resnet18(x)
        features_tree = features.view(-1, 1, 512)
        features_tree = self.fc_tree_net(features_tree, embedding, indicator)
        final_features = features + alpha * features_tree
        output = self.mlp(final_features)
        pred = output[:,0:8]
        meta_target_pred = output[:,8:17]
        meta_struct_pred = output[:,17:38]
        return pred, meta_target_pred, meta_struct_pred


class RAVENDataset(Dataset):
    def __init__(self, data_dir, split="test", img_size=224):
        self.data_dir = data_dir
        self.split = split
        self.img_size = img_size

        # Find all test files
        self.files = sorted(glob.glob(os.path.join(data_dir, f"*_{split}.npz")))

        if len(self.files) == 0:
            raise ValueError(f"No {split} files found in {data_dir}")

        print(f"Found {len(self.files)} files for {split} split")

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        data = np.load(self.files[idx])


        image = data["image"]
        target = data["target"]


        meta_target = data.get("meta_target", np.zeros(9))
        if not isinstance(meta_target, np.ndarray):
            meta_target = np.array([meta_target])
        if meta_target.size < 9:
            meta_target = np.pad(meta_target, (0, 9 - meta_target.size))


        meta_structure = data.get("meta_structure", np.zeros(21))
        if not isinstance(meta_structure, np.ndarray):
            meta_structure = np.array([meta_structure])
        if meta_structure.size < 21:
            meta_structure = np.pad(meta_structure, (0, 21 - meta_structure.size))


        embedding = np.zeros((6, 300), dtype=np.float32)
        indicator = np.array([1.0], dtype=np.float32)


        if isinstance(target, np.ndarray):
            target = int(target.item()) if target.size == 1 else int(target)
        else:
            target = int(target)


        image = torch.FloatTensor(image).float()
        target = torch.LongTensor([target]).squeeze()
        meta_target = torch.FloatTensor(meta_target).float()
        meta_structure = torch.FloatTensor(meta_structure).float()
        embedding = torch.FloatTensor(embedding).float()
        indicator = torch.FloatTensor(indicator).float()

        return image, target, meta_target, meta_structure, embedding, indicator


def evaluate_checkpoint(model, dataloader, use_cuda):
    """Evaluate a single checkpoint on a dataset"""
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for batch_idx, (image, target, meta_target, meta_structure, embedding, indicator) in enumerate(dataloader):
            if use_cuda:
                image = image.cuda()
                target = target.cuda()
                embedding = embedding.cuda()
                indicator = indicator.cuda()


            output = model(image, embedding, indicator)
            pred = output[0]

            pred_label = pred.argmax(dim=1)
            correct += (pred_label == target).sum().item()
            total += target.size(0)


            if (batch_idx + 1) % 10 == 0:
                print(f"  Batch {batch_idx + 1}/{len(dataloader)}", end='\r')

    accuracy = correct / total if total > 0 else 0.0
    return accuracy

def extract_epoch(path):
    """Extract epoch number from checkpoint filename"""
    basename = os.path.basename(path)
    try:
        parts = basename.replace('.pth', '').split('_')
        for i, part in enumerate(parts):
            if part == 'epoch' or part == 'ep':
                return int(parts[i+1])
    except:
        pass
    return 0


def main():

    checkpoint_dir = '/content/drive/MyDrive/Human and Machine Learning/checkpoint'
    raven_base_dir = '/content/drive/MyDrive/Human and Machine Learning/RAVEN-10000'
    batch_size = 32
    device = 0
    img_size = 160
    output_csv = 'evaluation_results.csv'

    use_cuda = torch.cuda.is_available()
    if use_cuda:
        torch.cuda.set_device(device)
        print(f"Using GPU: {torch.cuda.get_device_name(device)}")
    else:
        print("Using CPU")


    print(f"\nLooking for checkpoints in: {checkpoint_dir}")
    print(f"Directory exists: {os.path.exists(checkpoint_dir)}")

    if not os.path.exists(checkpoint_dir):
        print("ERROR: Checkpoint directory not found!")
        return


    all_files = os.listdir(checkpoint_dir)
    checkpoint_files = [os.path.join(checkpoint_dir, f) for f in all_files if f.endswith('.pth')]
    checkpoint_files = sorted(checkpoint_files, key=extract_epoch)

    if not checkpoint_files:
        print(f"ERROR: No .pth files found in {checkpoint_dir}")
        print(f"Files in directory: {all_files}")
        return

    dataset_dirs = []
    if os.path.exists(raven_base_dir):
        for item in os.listdir(raven_base_dir):
            item_path = os.path.join(raven_base_dir, item)
            if os.path.isdir(item_path) and item not in ['.ipynb_checkpoints', '__pycache__']:
                test_files = glob.glob(os.path.join(item_path, '*test.npz'))
                if test_files:
                    dataset_dirs.append(item_path)

    dataset_dirs = sorted(dataset_dirs)

    print(f"\nFound {len(checkpoint_files)} checkpoint files")
    print(f"Found {len(dataset_dirs)} dataset directories:")
    for d in dataset_dirs:
        print(f"  - {os.path.basename(d)}")
    print()


    results_by_dataset = {}

    for dataset_dir in dataset_dirs:
        dataset_name = os.path.basename(os.path.normpath(dataset_dir))
        results_by_dataset[dataset_name] = []

        print(f"Dataset: {dataset_name}")



        try:
            test_data = RAVENDataset(dataset_dir, "test", img_size)
            testloader = DataLoader(test_data, batch_size=batch_size,
                                   shuffle=False, num_workers=0)
        except Exception as e:
            print(f"ERROR loading dataset: {str(e)}")
            continue


        for ckpt_idx, ckpt_path in enumerate(checkpoint_files):
            ckpt_name = os.path.basename(ckpt_path)
            epoch_num = extract_epoch(ckpt_path)

            print(f"Loading checkpoint {ckpt_idx + 1}/{len(checkpoint_files)}: {ckpt_name}...", end=' ')

            try:
                model = Resnet18_MLP(img_size=img_size)


                checkpoint = torch.load(ckpt_path, map_location='cpu', weights_only=False)

                if isinstance(checkpoint, dict):
                    if 'state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['state_dict'])
                    elif 'model_state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['model_state_dict'])
                    else:
                        model.load_state_dict(checkpoint)
                else:
                    model.load_state_dict(checkpoint)

                if use_cuda:
                    model = model.cuda()

                print("Evaluating...")


                accuracy = evaluate_checkpoint(model, testloader, use_cuda)
                accuracy_pct = accuracy * 100

                print(f"{ckpt_name}: {accuracy_pct:.4f}")

                results_by_dataset[dataset_name].append({
                    'checkpoint': ckpt_name,
                    'epoch': epoch_num,
                    'accuracy': accuracy_pct
                })


                if use_cuda:
                    del model
                    torch.cuda.empty_cache()

            except Exception as e:
                import traceback
                print(f"\n{ckpt_name}: ERROR - {str(e)}")
                traceback.print_exc()
                results_by_dataset[dataset_name].append({
                    'checkpoint': ckpt_name,
                    'epoch': epoch_num,
                    'accuracy': f'ERROR: {str(e)}'
                })

        print()


    print(f"Saving results to {output_csv}")


    csv_results = []
    for dataset_name, dataset_results in results_by_dataset.items():
        for result in dataset_results:
            csv_results.append({
                'dataset': dataset_name,
                'checkpoint': result['checkpoint'],
                'epoch': result['epoch'],
                'accuracy': result['accuracy']
            })

    with open(output_csv, 'w', newline='') as csvfile:
        fieldnames = ['dataset', 'checkpoint', 'epoch', 'accuracy']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for result in csv_results:
            writer.writerow(result)

    print("FINAL SUMMARY")


    for dataset_name in sorted(results_by_dataset.keys()):
        print(f"Dataset: {dataset_name}")
        for result in results_by_dataset[dataset_name]:
            if isinstance(result['accuracy'], float):
                print(f"{result['checkpoint']}: {result['accuracy']:.4f}")
            else:
                print(f"{result['checkpoint']}: {result['accuracy']}")
        print()

    print(f"Detailed results saved to: {output_csv}")

if __name__ == '__main__':
    main()
